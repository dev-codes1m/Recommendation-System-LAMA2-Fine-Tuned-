{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_huggingface import  HuggingFaceEmbeddings\n",
    "import os\n",
    "from langchain_groq import ChatGroq\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "api_key = os.getenv(\"GROQ_API_KEY\")\n",
    "os.getenv(\"HF_TOKEN\")\n",
    "llm = ChatGroq(model_name = \"Gemma-7b-It\",groq_api_key=api_key)\n",
    "embeddings=HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "review_text =FAISS.load_local(\"reviewText_store\",embeddings,allow_dangerous_deserialization=True)\n",
    "summary_store =FAISS.load_local(\"summary_store\",embeddings,allow_dangerous_deserialization=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import create_retrieval_chain\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "from langchain_core.prompts import ChatPromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "review_retriver = review_text.as_retriever()\n",
    "summary_retriver = summary_store.as_retriever()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retriver Chain(For Review Text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt_review_text = (\n",
    "    \"You are an Expert Recommendation System \"\n",
    "    \"Use the following pieces of retrived context to recommened \"\n",
    "    \"based on user query \"\n",
    "    \"Suggest Top 3 Best Product Name Only\"\n",
    "    \"Do Not Generate Provided Thing Out Of Provided {context}\"\n",
    "    \"Do Not Provide Any Additional Information Out Of {context}\"\n",
    "    \"\\n\\n\"\n",
    "    \"{context}\"\n",
    ")\n",
    "\n",
    "prompt_review_text = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "    (\"system\",system_prompt_review_text),\n",
    "    (\"human\", \"{input}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "question_answer_chain_review = create_stuff_documents_chain(llm,prompt_review_text)\n",
    "rag_chain_review = create_retrieval_chain(review_retriver,question_answer_chain_review)\n",
    "\n",
    "# response = rag_chain_review.invoke({\"input\":\"jack stands\"})\n",
    "\n",
    "# response['answer']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retriver Chain(For Summary Text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt_summary_text = (\n",
    "    \"You are an Expert Recommendation System \"\n",
    "    \"Use the following pieces of summary context to recommened \"\n",
    "    \"based on user query \"\n",
    "    \"Suggest Best Top 3 Review For Product Asked By User From {context}\"\n",
    "    \"Do Not Generate Provided Thing Out Of Provided {context}\"\n",
    "    \"Do Not Provide Any Additional Information Out Of {context}\"\n",
    "    \"\\n\\n\"\n",
    "    \"{context}\"\n",
    ")\n",
    "\n",
    "prompt_summary_text = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "    (\"system\",system_prompt_summary_text),\n",
    "    (\"human\", \"{input}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "question_answer_chain_summary = create_stuff_documents_chain(llm,prompt_summary_text)\n",
    "rag_chain_summary = create_retrieval_chain(summary_retriver,question_answer_chain_summary)\n",
    "\n",
    "# response = rag_chain_summary.invoke({\"input\":\"jack stands\"})\n",
    "\n",
    "# response['answer']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final RAG Recommendation System"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import LLMChain\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "def generate_final_prompt(review_response, summary_response, query):\n",
    "    \"\"\"Generate the final prompt for the LLMChain\"\"\"\n",
    "    prompt = (\n",
    "        \"You Are An Expert Product Recommender \"\n",
    "        \"Provide Top Product Name\"\n",
    "        \"Based On {review}, {summary} Only \"\n",
    "        \"For The User Query: {query} \"\n",
    "        \"Do Not Generate Provided Thing Out Of Provided {review}, {summary}\"\n",
    "        \"Do Not Provide Any Additional Information Out Of {review}, {summary}\"\n",
    "        \"Provide Name Of Product Given In {review}, {summary} Only No Other Information Required\"\n",
    "    ).format(review=review_response, summary=summary_response, query=query)\n",
    "    return prompt\n",
    "\n",
    "def recommendation(query):\n",
    "    \"\"\"Provide a product recommendation based on the user query\"\"\"\n",
    "    review_response = rag_chain_review.invoke({\"input\": query})\n",
    "    summary_response = rag_chain_summary.invoke({\"input\": query})\n",
    "    final_prompt = generate_final_prompt(review_response['answer'], summary_response['answer'], query)\n",
    "    # print(\"Final Prompt: \", final_prompt)\n",
    "    prompt_template = PromptTemplate(input_variables=[\"query\"], template=final_prompt)\n",
    "    chain = LLMChain(llm=llm, prompt=prompt_template)\n",
    "    response = chain({\"query\": query})\n",
    "    return response['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**Product Name:** California Car Duster\n"
     ]
    }
   ],
   "source": [
    "print(recommendation(\"Car Duster\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- **K&N Air Filter**\n",
      "- **Fram Air Filter**\n",
      "- **ACDelco Air Filter**\n"
     ]
    }
   ],
   "source": [
    "print(recommendation(\"Air Filter\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## Top Product Recommendations Based On Provided Reviews:\n",
      "\n",
      "**1. LEDGLOW KIT 31mm Festoon 12 LEDs SMD LED Bulb White**\n",
      "\n",
      "* This product received the highest praise in the provided reviews, with one reviewer calling them \"freaking awesome\" and praising their effectiveness and quality.\n",
      "\n",
      "\n",
      "**2. Led Bulbs 31mm Festoon LED Light Bulbs (12-Pack White)**\n",
      "\n",
      "* This product received two highly positive reviews, with one reviewer calling them the \"best LEDs on Amazon.\" Reviewers praised their quality, functionality, and overall performance.\n",
      "\n",
      "\n",
      "**3. Led Bulbs 31mm Festoon LED Light Bulbs (6-Pack White)**\n",
      "\n",
      "* While this product only had one review, it received a positive review that praised its ease of installation and effectiveness.\n",
      "\n",
      "**Additional Notes:**\n",
      "\n",
      "* All three recommended products received positive feedback for their quality, effectiveness, and ease of installation.\n",
      "* The LEDGLOW KIT product seemed to impress reviewers the most, likely due to its combination of effectiveness and awesomeness.\n",
      "* The Led Bulbs (12-Pack) option also received high praise, suggesting it offers excellent value for its price.\n"
     ]
    }
   ],
   "source": [
    "print(recommendation(\"LED Lights\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mynewenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
